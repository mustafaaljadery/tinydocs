# Getting Started

tinygrad is a framework that makes it extremely simple to build and train neural networks.

## Installation from source

The current recommended way to install tinygrad is from source.

```bash
git clone https://github.com/tinygrad/tinygrad.git
cd tinygrad
python3 -m pip install -e .
```

Don't forget the `.` at the end!

## Installation with pip

```bash
pip install tinygrad
```

## NN example
```python copy
from tinygrad.tensor import Tensor
import tinygrad.nn.optim as optim

class TinyBobNet:
  def __init__(self):
    self.l1 = Tensor.uniform(784, 128)
    self.l2 = Tensor.uniform(128, 10)

  def forward(self, x):
    return x.dot(self.l1).relu().dot(self.l2).log_softmax()

model = TinyBobNet()
optim = optim.SGD([model.l1, model.l2], lr=0.001)

# ... complete data loader here

out = model.forward(x)
loss = out.mul(y).mean()
optim.zero_grad()
loss.backward()
optim.step()
```

## Imports to get Started
```python copy
import numpy as np
from tinygrad.helpers import Timing
```

## Tensors

Importing tensor class

```python copy
from tinygrad.tensor import Tensor
```

Tensors can be created